{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0d5efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de975b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 만들어주는 함수 정의\n",
    "def get_sequencial_model(imput_shape):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(input_shape), # 입력층 만듦 -> 은닉층으로 데이터를 보낼거임\n",
    "            \n",
    "            # 1st\n",
    "            # 64개의 데이터 받음(필터 64개 사용). 3x3 필터크기. 패딩을 자동으로 삽입해서 크기 유지(<-> 'valid')\n",
    "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
    "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
    "            # 가중치 2번 업데이트. 좀 더 세밀해짐.\n",
    "            layers.MaxPool2D(), # 가장 큰 값을 뽑아서 크기를 줄여줌\n",
    "            layers.BatchNormalization(), # 픽셀값을 정규화.\n",
    "            layers.Dropout(0.5), # 과대적합 방지를 위해\n",
    "            \n",
    "            # 2nd\n",
    "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'), # 128개 데이터 추출\n",
    "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
    "            layers.MaxPool2D(), \n",
    "            layers.BatchNormalization(), \n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            # FC\n",
    "            layers.GlobalMaxPool2D(), # 다합쳐서 맥스풀링\n",
    "            layers.Dense(128, activation=\"relu\"), # Dence : 일반 레이어\n",
    "            layers.Dense(1, activation='sigmoid') # 참/거짓 둘 중 하나로 값 추출되도록\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699e3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "model = get_sequencial_model(input_shape)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics='accuracy' # 검증방법\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd380457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size, mode='train', shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.csv_path = csv_path\n",
    "        self.fold = fold\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)  \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = (idx+1) * self.batch_size\n",
    "        data = self.df.iloc[start:end]\n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "    \n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for _, r in data.iterrows():\n",
    "            file_name = r['file_name']\n",
    "            image = cv2.imread(f'data/images/{file_name}.jpg')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            image = image / 255.\n",
    "\n",
    "            label = int(r['species']) - 1\n",
    "\n",
    "            batch_x.append(image)\n",
    "            batch_y.append(label)\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb62be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'data/kfolds.csv'\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    batch_size=128,\n",
    "    csv_path = csv_path,\n",
    "    fold=1,\n",
    "    image_size=256,\n",
    "    mode='train',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    batch_size=128,\n",
    "    csv_path = csv_path,\n",
    "    fold=1,\n",
    "    image_size=256,\n",
    "    mode='val',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96372a",
   "metadata": {},
   "source": [
    "첫 번째 콜백 : 어떻게 멈출것인지 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ce7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EalryStopping : Epoch을 많이 돌린 후 특정 시점에 멈추게 함\n",
    "# monitor : EarlyStopping의 기준이 되는 값. 예) val_loss 더이상 감소되지 않을 경우 EarlyStopping 적용\n",
    "# patience : Training이 진행됨에도 더이상 monitor되는 값의 개선이 없을 경우 몇번 epoch을 진행할 지 설정. 몇번이상 변화가 없으면 멈출지를 설정 가능\n",
    "# mode : monitor되는 값이 최소가 되야 하는지, 최대가 되어야 하는지 설정\n",
    "# restore_best_weights : true로 설정하면 training이 끝난 후 model의 weight를 monitor하고 있던 값이 가장\n",
    "# 좋았을 경우와 weight로 복원. False라면 마지막 training이 끝난 후의 weight로 설정\n",
    "\n",
    "# setting 객체 만들어놓기\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 3, # 3번 이상 좋아지지 않으면 멈출거임\n",
    "    mode='min',\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ac755",
   "metadata": {},
   "source": [
    "두 번째 콜백: 상태가 좋지 않았을 때 어떻게 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c37f1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau : 모델의 개선이 없을 경우 learning rate를 조절해 모델의 개선을 유도함\n",
    "# monitor : ReduceLROnPlateau의 기준이 되는 값. val_loss가 더이상 감소되지 않을 경우 ReduceLROnPlateau 적용\n",
    "# factor : learning rate를 얼마나 변경시킬 것인지 정하는 값. learning rate * factor\n",
    "# patience : training이 진행됨에도 더이상 monitor되는 값의 개선이 없을 경우 최적의 monitor값을 기준으로\n",
    "# 몇 번의 epoch을 진행하고 learning rate를 조절할지를 값을 설정.\n",
    "\n",
    "reduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',\n",
    "    factor = 0.1, # 수정할 때 얼마를 더 곱해줄지를 설정\n",
    "    patience = 10, # 10번 좋아지지 않으면 적용하겠다.\n",
    "    mode = 'min',\n",
    "    min_lr = 0.0001 # 계속 값이 작아지기 때문에 제한을 둠\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45d3f0",
   "metadata": {},
   "source": [
    "세 번째 콜백 : 어떻게 로그를 저장할 지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edaf0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint : 모델의 경로 설정\n",
    "# 모델 경로를 '{epoch:02d}-{val_loss:.2f}.hdf5' 라고 하면 앞의 명시한 문자열로 파일을 저장\n",
    "# 예) 01-0.12f.h5\n",
    "# save_weight_only : True(weight만 저장), False(모델, layer, weight 모두 저장)\n",
    "# save_best_only : True(모델의 정확도가 최고값을 갱신했을 때만 저장), False(매회 저장)\n",
    "\n",
    "filepath = '{epoch:02d}-{val_loss:.2f}.hdf5' # 예) 01-0.12f.h5\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, \n",
    "    moniter='val_loss',\n",
    "    save_weight_only=True,\n",
    "    save_best_only=False,\n",
    "    mode='min',\n",
    "    verbose=1 # 에폭 돌때마다 설명출력해줌\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70f7673b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 1635s 35s/step - loss: 1.0324 - accuracy: 0.6532 - val_loss: 0.6261 - val_accuracy: 0.6782 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 1699s 37s/step - loss: 0.6251 - accuracy: 0.6738 - val_loss: 0.6242 - val_accuracy: 0.6810 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 1385s 30s/step - loss: 0.6279 - accuracy: 0.6726 - val_loss: 0.6346 - val_accuracy: 0.6762 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 1364s 30s/step - loss: 0.6143 - accuracy: 0.6828 - val_loss: 0.6297 - val_accuracy: 0.6782 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 1501s 33s/step - loss: 0.6136 - accuracy: 0.6794 - val_loss: 0.6203 - val_accuracy: 0.6769 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 1407s 31s/step - loss: 0.6049 - accuracy: 0.6863 - val_loss: 0.6153 - val_accuracy: 0.6769 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 1406s 31s/step - loss: 0.5982 - accuracy: 0.6880 - val_loss: 0.6120 - val_accuracy: 0.6789 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 1398s 30s/step - loss: 0.5955 - accuracy: 0.6921 - val_loss: 0.6137 - val_accuracy: 0.6810 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 1388s 30s/step - loss: 0.5766 - accuracy: 0.6962 - val_loss: 0.6916 - val_accuracy: 0.5048 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 1382s 30s/step - loss: 0.5792 - accuracy: 0.7016 - val_loss: 0.6151 - val_accuracy: 0.7109 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        reduce_on_plateau,\n",
    "        model_checkpoint\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d936d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
