{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A1Rots52MU5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoHV_pc0AusC"
      },
      "source": [
        "## RNN with a simple example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IrSaqim2RCM"
      },
      "source": [
        "HIDDEN_DIM = 35 # hidden state의 size\n",
        "LEARNING_RATE = 0.01\n",
        "EPOCHS = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8BT2CWM2cU7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSTLlt5k2sOh"
      },
      "source": [
        "string = \"hello pytorch and data analytics.\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk1PgbXb3fr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65a9bd1-010f-4b6e-b227-426f2cec03bc"
      },
      "source": [
        "chars = \"abcdefghijklmnopqrstuvwxyz .01\" # 알파벳, 공백, 콤마, 01(start와 end를 구분하기 위해서)\n",
        "char_list = [i for i in chars]\n",
        "n_letters = len(char_list)\n",
        "n_letters\n",
        "# 원핫인코딩으로 임베딩하면 임베딩이 30차원이 됨"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsxIdHCG3kCt"
      },
      "source": [
        "def string_to_onehot(string):\n",
        "    start = np.zeros(shape = n_letters, dtype = int)\n",
        "    end = np.zeros(shape = n_letters, dtype = int)\n",
        "\n",
        "    start[-2] = 1\n",
        "    end[-1] = 1\n",
        "\n",
        "    for i in string:\n",
        "        idx = char_list.index(i)\n",
        "        zero = np.zeros(shape = n_letters, dtype = int)\n",
        "        zero[idx] = 1\n",
        "        start = np.vstack([start, zero])\n",
        "    output = np.vstack([start, end])\n",
        "    return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT4kKYRi4Ocg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac68c87-1ea6-4342-f58c-5e292cdf21a5"
      },
      "source": [
        "string_to_onehot(\"data\")\n",
        "# 처음과 끝 벡터에는 설정한 자라에 1이 들어간 것을 확인 가능"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPIUsEBV2MQ3"
      },
      "source": [
        "# 디코딩해주는 함수 정의\n",
        "def onehot_to_string(onehot):\n",
        "    onehot_value = torch.Tensor.numpy(onehot)\n",
        "    return char_list[onehot_value.argmax()]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sj0QMsH2MIu"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.input2hidden = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden2hidden = nn.Linear(hidden_size, hidden_size)\n",
        "        self.hidden2output = nn.Linear(hidden_size, output_size)\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        hidden = self.act_fn(self.input2hidden(input) + self.hidden2hidden(hidden))\n",
        "        output = self.hidden2output(hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self): # hidden vector를 초기화 시켜주는 함수\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoDJ1uvE7G4P"
      },
      "source": [
        "rnn = RNN(n_letters, HIDDEN_DIM, n_letters).to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGzInpZHPSGo",
        "outputId": "a9ff3e17-3d85-489b-985b-0d6e0d8bb976"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (input2hidden): Linear(in_features=30, out_features=35, bias=True)\n",
            "  (hidden2hidden): Linear(in_features=35, out_features=35, bias=True)\n",
            "  (hidden2output): Linear(in_features=35, out_features=30, bias=True)\n",
            "  (act_fn): Tanh()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23--JfwD7axN"
      },
      "source": [
        "loss_func = nn.MSELoss().to(device)\n",
        "optimizer_rnn = torch.optim.Adam(rnn.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYbiDE7e7zgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c6705f-2a6a-4085-f7e7-9d191706b38a"
      },
      "source": [
        "rnn.parameters"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of RNN(\n",
              "  (input2hidden): Linear(in_features=30, out_features=35, bias=True)\n",
              "  (hidden2hidden): Linear(in_features=35, out_features=35, bias=True)\n",
              "  (hidden2output): Linear(in_features=35, out_features=30, bias=True)\n",
              "  (act_fn): Tanh()\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4dFUSgp8I54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15af0a3f-276b-430b-8d25-a89feb396e08"
      },
      "source": [
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    optimizer_rnn.zero_grad()\n",
        "    hidden = rnn.init_hidden()\n",
        "    total_loss = 0\n",
        "\n",
        "    for j in range(one_hot.size()[0]-1):\n",
        "        input_ = one_hot[j:j+1, :].to(device)\n",
        "        target = one_hot[j+1].to(device)\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        loss = loss_func(output.view(-1), target.view(-1))\n",
        "        total_loss += loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer_rnn.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(total_loss)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0107, grad_fn=<AddBackward0>)\n",
            "tensor(0.0047, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luZcsFpB9EA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef1a71b-6750-4833-8623-02db391946da"
      },
      "source": [
        "start_tkn = torch.zeros(1, n_letters)\n",
        "start_tkn[:, -2] = 1 # start_token\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden = rnn.init_hidden() # 초기화\n",
        "    input_ = start_tkn.to(device)\n",
        "    output_string = \"\"\n",
        "\n",
        "    for i in range(len(string)):\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        output_string += onehot_to_string(output.data)\n",
        "        input_ = output\n",
        "\n",
        "print(output_string)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello pytorch and data anddich ad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo4bJdC7Azdi"
      },
      "source": [
        "## RNN and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHO2B1thAPOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a53f79-3a45-4205-ff9f-58f821c99941"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-30 11:52:03--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-11-30 11:52:03 (20.6 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUTIUDW9Ezyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611d86ea-a5e6-48c3-b6ab-5e9c396beb80"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Y4EMWTEnCo"
      },
      "source": [
        "import re\n",
        "import unidecode\n",
        "import random\n",
        "import string\n",
        "import time, math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o10hD8eAE4s0"
      },
      "source": [
        "EPOCHS = 1000\n",
        "HIDDEN_DIM = 100\n",
        "BATCH_SIZE = 1\n",
        "CHUNK_LEN = 250 # 데이터 일부만 추출하여 학습하기 위해서\n",
        "NUM_LAYERS = 1 # 1층 RNN\n",
        "EMBEDDING = 70 # 임베딩 벡터 차원 수\n",
        "LEARNING_RATE = 0.004"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UFfZrVIFJ0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "40152e05-beed-48e9-9507-18a98d82c739"
      },
      "source": [
        "characters = string.printable\n",
        "n_characters = len(characters)\n",
        "characters"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_YtRGWZFaMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ea1c22-da58-4f3b-b15d-853e6cd44d41"
      },
      "source": [
        "text_file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "len_text_file = len(text_file)\n",
        "len_text_file"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyzuBNT9Fqhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3ac4fd-0a6f-48e7-9a56-f08b9f7a7d7f"
      },
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, len_text_file - CHUNK_LEN)\n",
        "    end_index = start_index + CHUNK_LEN + 1\n",
        "    return text_file[start_index : end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce of England and our persons' safety,\n",
            "Enforced us to this execution?\n",
            "\n",
            "Lord Mayor:\n",
            "Now, fair befall you! he deserved his death;\n",
            "And you my good lords, both have well proceeded,\n",
            "To warn false traitors from the like attempts.\n",
            "I never look'd for better a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc_drwFuFJwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de7c5c1-9df0-4328-997e-16280980ccaf"
      },
      "source": [
        "def character_to_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for char in range(len(string)):\n",
        "        tensor[char] = characters.index(string[char])\n",
        "    return tensor\n",
        "\n",
        "print(character_to_tensor('ABCde'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OeHNVC2J-6U"
      },
      "source": [
        "def random_training_set():\n",
        "    chunk = random_chunk()\n",
        "    input = character_to_tensor(chunk[:-1])\n",
        "    target = character_to_tensor(chunk[1:])\n",
        "    return input, target"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA7jZK6fKMwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e85000-f0bc-400a-92e5-2bfff593d8b8"
      },
      "source": [
        "random_training_set()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([13, 14, 10, 27, 94, 28, 14, 27, 31, 18, 12, 14, 28, 96, 51, 10, 28, 29,\n",
              "         94, 10, 23, 13, 94, 29, 24, 94, 12, 24, 22, 14, 73, 94, 29, 17, 10, 29,\n",
              "         94, 34, 24, 30, 94, 13, 24, 94, 12, 17, 10, 23, 16, 14, 94, 29, 17, 18,\n",
              "         28, 94, 25, 30, 27, 25, 24, 28, 14, 73, 96, 58, 17, 18, 12, 17, 94, 11,\n",
              "         14, 18, 23, 16, 94, 28, 24, 94, 17, 24, 27, 27, 18, 11, 21, 14, 73, 94,\n",
              "         28, 24, 94, 11, 21, 24, 24, 13, 34, 73, 94, 22, 30, 28, 29, 96, 47, 14,\n",
              "         10, 13, 94, 24, 23, 94, 29, 24, 94, 28, 24, 22, 14, 94, 15, 24, 30, 21,\n",
              "         94, 18, 28, 28, 30, 14, 77, 94, 32, 14, 94, 10, 21, 21, 94, 20, 23, 14,\n",
              "         14, 21, 75, 96, 96, 47, 40, 50, 49, 55, 40, 54, 77, 96, 44, 94, 10, 22,\n",
              "         94, 10, 94, 15, 14, 10, 29, 17, 14, 27, 94, 15, 24, 27, 94, 14, 10, 12,\n",
              "         17, 94, 32, 18, 23, 13, 94, 29, 17, 10, 29, 94, 11, 21, 24, 32, 28, 77,\n",
              "         96, 54, 17, 10, 21, 21, 94, 44, 94, 21, 18, 31, 14, 94, 24, 23, 94, 29,\n",
              "         24, 94, 28, 14, 14, 94, 29, 17, 18, 28, 94, 11, 10, 28, 29, 10, 27, 13,\n",
              "         94, 20, 23, 14, 14, 21, 96, 36, 23, 13, 94, 12, 10, 21, 21, 94]),\n",
              " tensor([14, 10, 27, 94, 28, 14, 27, 31, 18, 12, 14, 28, 96, 51, 10, 28, 29, 94,\n",
              "         10, 23, 13, 94, 29, 24, 94, 12, 24, 22, 14, 73, 94, 29, 17, 10, 29, 94,\n",
              "         34, 24, 30, 94, 13, 24, 94, 12, 17, 10, 23, 16, 14, 94, 29, 17, 18, 28,\n",
              "         94, 25, 30, 27, 25, 24, 28, 14, 73, 96, 58, 17, 18, 12, 17, 94, 11, 14,\n",
              "         18, 23, 16, 94, 28, 24, 94, 17, 24, 27, 27, 18, 11, 21, 14, 73, 94, 28,\n",
              "         24, 94, 11, 21, 24, 24, 13, 34, 73, 94, 22, 30, 28, 29, 96, 47, 14, 10,\n",
              "         13, 94, 24, 23, 94, 29, 24, 94, 28, 24, 22, 14, 94, 15, 24, 30, 21, 94,\n",
              "         18, 28, 28, 30, 14, 77, 94, 32, 14, 94, 10, 21, 21, 94, 20, 23, 14, 14,\n",
              "         21, 75, 96, 96, 47, 40, 50, 49, 55, 40, 54, 77, 96, 44, 94, 10, 22, 94,\n",
              "         10, 94, 15, 14, 10, 29, 17, 14, 27, 94, 15, 24, 27, 94, 14, 10, 12, 17,\n",
              "         94, 32, 18, 23, 13, 94, 29, 17, 10, 29, 94, 11, 21, 24, 32, 28, 77, 96,\n",
              "         54, 17, 10, 21, 21, 94, 44, 94, 21, 18, 31, 14, 94, 24, 23, 94, 29, 24,\n",
              "         94, 28, 14, 14, 94, 29, 17, 18, 28, 94, 11, 10, 28, 29, 10, 27, 13, 94,\n",
              "         20, 23, 14, 14, 21, 96, 36, 23, 13, 94, 12, 10, 21, 21, 94, 22]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPhplF0Ru6a9"
      },
      "source": [
        "### Make RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh3P9qxiGnOk"
      },
      "source": [
        "class EN_RNN_DE(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
        "        super(EN_RNN_DE, self).__init__()\n",
        "\n",
        "        self.input_size = input_size # 100\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers)\n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        en_output = self.encoder(input.view(1, -1)) # flatten된 형태로 통과\n",
        "        output, hidden = self.rnn(en_output, hidden)\n",
        "        de_output = self.decoder(output.view(1, -1)) # flatten된 형태로 통과\n",
        "        return de_output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
        "        return hidden"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-P52tmBGnKa"
      },
      "source": [
        "model = EN_RNN_DE(n_characters, EMBEDDING, HIDDEN_DIM, n_characters, NUM_LAYERS).to(device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvU9Ix01MtXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fe144b-99fc-43e4-d97f-004c9d4115b7"
      },
      "source": [
        "inp = character_to_tensor(\"A\")\n",
        "print(inp.size())\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "out,hidden = model(inp,hidden)\n",
        "print(hidden.size())\n",
        "print(out.size())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPc_WL61Bvl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079b946b-0a4e-4703-e40c-b3aa52992efc"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EN_RNN_DE(\n",
            "  (encoder): Embedding(100, 70)\n",
            "  (rnn): RNN(70, 100)\n",
            "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEMgXm97Gm4K"
      },
      "source": [
        "optimizer_model = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsSNaVDNJnUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0adbe24f-ac15-45fd-b655-88cdaa9136df"
      },
      "source": [
        "for i in range(EPOCHS):\n",
        "    input, target = random_training_set()\n",
        "    input = input.to(device)\n",
        "    target = target.to(device)\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer_model.zero_grad()\n",
        "\n",
        "    for j in range(CHUNK_LEN-1):\n",
        "        x = input[j]\n",
        "        y_ = target[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y, hidden = model(x, hidden)\n",
        "        loss += loss_func(y, y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer_model.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(loss/CHUNK_LEN)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.6278], grad_fn=<DivBackward0>)\n",
            "tensor([2.3878], grad_fn=<DivBackward0>)\n",
            "tensor([2.2159], grad_fn=<DivBackward0>)\n",
            "tensor([2.0908], grad_fn=<DivBackward0>)\n",
            "tensor([1.9464], grad_fn=<DivBackward0>)\n",
            "tensor([1.9986], grad_fn=<DivBackward0>)\n",
            "tensor([2.1181], grad_fn=<DivBackward0>)\n",
            "tensor([2.0662], grad_fn=<DivBackward0>)\n",
            "tensor([1.7870], grad_fn=<DivBackward0>)\n",
            "tensor([1.8726], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_lp1RvesKro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e79ba5e-8242-4a28-b02a-367d30f7a444"
      },
      "source": [
        "start_string = \"b\"\n",
        "\n",
        "input = character_to_tensor(start_string)\n",
        "hidden = model.init_hidden()\n",
        "\n",
        "print(start_string, end=\"\")\n",
        "\n",
        "for i in range(300):\n",
        "    output, hidden = model(input, hidden)\n",
        "\n",
        "    output_dist = output.data.view(-1).div(0.8).exp()\n",
        "    top_i = torch.multinomial(output_dist, 1)[0]\n",
        "    predicted_char = characters[top_i]\n",
        "\n",
        "    print(predicted_char, end=\"\")\n",
        "\n",
        "    input = character_to_tensor(predicted_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buth! Lost shouns not iake in this and losten.\n",
            "\n",
            "VOKINCE:\n",
            "But thensarings\n",
            "to have spongeson I waist the have sain cance And not aiter you sperser Or?\n",
            "\n",
            "DUKE OF OFTERO LINCENCES:\n",
            "Thine the werth her me const be in you? coury shall a prorray that hast him: I himsent with whanst chall your good you, me an"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9UZMUNIu_Zh"
      },
      "source": [
        "### Make LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYu5wa03vBRu"
      },
      "source": [
        "class EN_LSTM_DE(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
        "        super(EN_LSTM_DE, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers) \n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        en_output = self.encoder(input.view(1, -1))\n",
        "        output, (hidden, cell) = self.lstm(en_output, (hidden, cell)) # hidden와 cell이 동시에 들어감\n",
        "        de_output = self.decoder(output.view(1, -1))\n",
        "        return de_output, hidden, cell\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
        "        cell = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
        "        return hidden, cell"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYPo-9HLvvJF"
      },
      "source": [
        "model_LSTM = EN_LSTM_DE(n_characters, EMBEDDING, HIDDEN_DIM, n_characters, NUM_LAYERS).to(device)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG9Kb0auyMfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4feaca98-3546-474c-995e-77dc3af300d9"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EN_RNN_DE(\n",
            "  (encoder): Embedding(100, 70)\n",
            "  (rnn): RNN(70, 100)\n",
            "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7LJ0vVGsKlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805ee2b0-ab97-46bc-fb07-de74a286005f"
      },
      "source": [
        "input = character_to_tensor(\"A\")\n",
        "print(input)\n",
        "\n",
        "hidden, cell = model_LSTM.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "output, hidden, cell = model_LSTM(input, hidden, cell)\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1soDd8qbvtNU"
      },
      "source": [
        "optimizer_lstm = torch.optim.Adam(model_LSTM.parameters(), lr = LEARNING_RATE)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmsoQgKByvJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff12c6d-e01f-490b-a876-1545f1a817cd"
      },
      "source": [
        "for i in range(EPOCHS):\n",
        "    input, target = random_training_set()\n",
        "    input = input.to(device)\n",
        "    target = target.to(device)\n",
        "    hidden, cell = model_LSTM.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer_lstm.zero_grad()\n",
        "\n",
        "    for j in range(CHUNK_LEN-1):\n",
        "        x = input[j]\n",
        "        y_ = target[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y, hidden, cell = model_LSTM(x, hidden, cell)\n",
        "        loss += loss_func(y, y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer_lstm.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(loss/CHUNK_LEN)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5857], grad_fn=<DivBackward0>)\n",
            "tensor([2.5657], grad_fn=<DivBackward0>)\n",
            "tensor([2.1868], grad_fn=<DivBackward0>)\n",
            "tensor([2.0831], grad_fn=<DivBackward0>)\n",
            "tensor([1.9339], grad_fn=<DivBackward0>)\n",
            "tensor([2.0539], grad_fn=<DivBackward0>)\n",
            "tensor([1.9564], grad_fn=<DivBackward0>)\n",
            "tensor([1.8441], grad_fn=<DivBackward0>)\n",
            "tensor([2.0637], grad_fn=<DivBackward0>)\n",
            "tensor([1.8053], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvJjMxcZvgSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871605d3-7a3b-4142-b14f-903d66410fce"
      },
      "source": [
        "start_string = \"b\"\n",
        "\n",
        "input = character_to_tensor(start_string)\n",
        "hidden, cell = model_LSTM.init_hidden()\n",
        "\n",
        "print(start_string, end=\"\")\n",
        "\n",
        "for i in range(300):\n",
        "    output, hidden, cell = model_LSTM(input, hidden, cell)\n",
        "\n",
        "    output_dist = output.data.view(-1).div(0.8).exp()\n",
        "    top_i = torch.multinomial(output_dist, 1)[0]\n",
        "    predicted_char = characters[top_i]\n",
        "\n",
        "    print(predicted_char, end=\"\")\n",
        "\n",
        "    input = character_to_tensor(predicted_char)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bars; and if and as and these preadess the peate tances as mipted me your shall for shall brow,-famabuines yef waspands warp but to my held with Mardafe,\n",
            "And the hea, sare to she lord weat is qubanding.\n",
            "\n",
            "LURENCIO:\n",
            "He as the worm faces and leaves proobed, if menders! I grays be and at wath he fears pe"
          ]
        }
      ]
    }
  ]
}